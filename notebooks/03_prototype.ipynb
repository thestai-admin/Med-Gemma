{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PrimaCare AI - Prototype\n",
    "\n",
    "**MedGemma Impact Challenge** - Working Prototype\n",
    "\n",
    "Complete diagnostic support system combining MedGemma + MedSigLIP.\n",
    "\n",
    "**Requirements:**\n",
    "- Kaggle GPU (T4/P100) or Colab GPU\n",
    "- HF_TOKEN secret\n",
    "- Accept terms: https://huggingface.co/google/medgemma-1.5-4b-it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for Colab:\n",
    "# !pip install -q -U transformers>=4.50.0 accelerate datasets pillow huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    raise RuntimeError(\"GPU required! Enable in Settings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    login(token=UserSecretsClient().get_secret(\"HF_TOKEN\"))\n",
    "    print(\"✓ Logged in via Kaggle\")\n",
    "except:\n",
    "    login()\n",
    "    print(\"✓ Logged in interactively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoProcessor, AutoModel\n",
    "\n",
    "print(\"Loading MedGemma...\")\n",
    "medgemma = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=\"google/medgemma-1.5-4b-it\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "print(\"✓ MedGemma loaded\")\n",
    "\n",
    "print(\"Loading MedSigLIP...\")\n",
    "siglip_model = AutoModel.from_pretrained(\"google/medsiglip-448\").to(\"cuda\")\n",
    "siglip_processor = AutoProcessor.from_pretrained(\"google/medsiglip-448\")\n",
    "print(\"✓ MedSigLIP loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "from PIL import Image\n\ndef analyze_image(image, prompt, max_tokens=2000):\n    \"\"\"Analyze medical image with MedGemma.\"\"\"\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    messages = [{\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": image},\n            {\"type\": \"text\", \"text\": prompt}\n        ]\n    }]\n    output = medgemma(text=messages, max_new_tokens=max_tokens)\n    return output[0][\"generated_text\"][-1][\"content\"]\n\n\ndef ask_question(question, max_tokens=1000):\n    \"\"\"Ask medical question without image.\"\"\"\n    # Note: image-text-to-text pipeline requires content as list of dicts\n    messages = [{\n        \"role\": \"user\",\n        \"content\": [{\"type\": \"text\", \"text\": question}]\n    }]\n    output = medgemma(text=messages, max_new_tokens=max_tokens)\n    return output[0][\"generated_text\"][-1][\"content\"]\n\n\ndef classify_image(image, labels):\n    \"\"\"Zero-shot classification with MedSigLIP.\"\"\"\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    inputs = siglip_processor(\n        text=labels, images=[image],\n        padding=\"max_length\", return_tensors=\"pt\"\n    ).to(\"cuda\")\n    with torch.no_grad():\n        outputs = siglip_model(**inputs)\n        probs = torch.softmax(outputs.logits_per_image, dim=1)[0]\n    return {label: prob.item() for label, prob in zip(labels, probs)}\n\n\nprint(\"✓ Functions ready\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. PrimaCare AI Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaCareAI:\n",
    "    \"\"\"Primary Care Diagnostic Support System.\"\"\"\n",
    "    \n",
    "    CXR_LABELS = [\n",
    "        \"normal chest x-ray\", \"pneumonia\", \"pleural effusion\", \n",
    "        \"cardiomegaly\", \"pulmonary edema\", \"atelectasis\",\n",
    "        \"pneumothorax\", \"consolidation\", \"mass or nodule\"\n",
    "    ]\n",
    "    \n",
    "    def analyze_xray(self, image, clinical_context=None):\n",
    "        \"\"\"Complete X-ray analysis pipeline.\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Step 1: Classification\n",
    "        print(\"  [1/4] Classifying...\")\n",
    "        results['classification'] = classify_image(image, self.CXR_LABELS)\n",
    "        \n",
    "        # Step 2: Findings\n",
    "        print(\"  [2/4] Extracting findings...\")\n",
    "        results['findings'] = analyze_image(image, \n",
    "            \"List all findings in this chest X-ray systematically.\")\n",
    "        \n",
    "        # Step 3: Differential\n",
    "        print(\"  [3/4] Generating differential...\")\n",
    "        context = f\"Clinical context: {clinical_context}\\n\" if clinical_context else \"\"\n",
    "        results['differential'] = analyze_image(image,\n",
    "            f\"{context}Provide differential diagnosis for this chest X-ray.\")\n",
    "        \n",
    "        # Step 4: Recommendations\n",
    "        print(\"  [4/4] Generating recommendations...\")\n",
    "        results['recommendations'] = analyze_image(image,\n",
    "            \"What follow-up or workup is recommended based on this X-ray?\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_report(self, image, patient_info=None):\n",
    "        \"\"\"Generate structured radiology report.\"\"\"\n",
    "        context = \"\"\n",
    "        if patient_info:\n",
    "            parts = []\n",
    "            if patient_info.get('age'): parts.append(f\"Age: {patient_info['age']}\")\n",
    "            if patient_info.get('gender'): parts.append(f\"Gender: {patient_info['gender']}\")\n",
    "            if patient_info.get('history'): parts.append(f\"History: {patient_info['history']}\")\n",
    "            context = \"\\n\".join(parts)\n",
    "        \n",
    "        prompt = f\"\"\"Generate a radiology report for this chest X-ray.\n",
    "{f'Patient: {context}' if context else ''}\n",
    "\n",
    "**TECHNIQUE:** [describe]\n",
    "**FINDINGS:** [systematic findings]\n",
    "**IMPRESSION:** [summary]\n",
    "**RECOMMENDATIONS:** [if any]\"\"\"\n",
    "        \n",
    "        return analyze_image(image, prompt, max_tokens=2000)\n",
    "\n",
    "\n",
    "primacare = PrimaCareAI()\n",
    "print(\"✓ PrimaCareAI initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Option 1: Load from dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"hf-vision/chest-xray-pneumonia\", split=\"train\", streaming=True)\n",
    "samples = list(dataset.take(3))\n",
    "print(f\"✓ Loaded {len(samples)} samples\")\n",
    "\n",
    "# Option 2: Sample from web\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"\n",
    "response = requests.get(url, headers={\"User-Agent\": \"MedGemma\"})\n",
    "web_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "print(\"✓ Web sample loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = samples[0]['image']\n",
    "label = \"Pneumonia\" if samples[0].get('label', 0) == 1 else \"Normal\"\n",
    "\n",
    "print(f\"Ground Truth: {label}\")\n",
    "display(test_image.resize((300, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running PrimaCare analysis...\\n\")\n",
    "results = primacare.analyze_xray(\n",
    "    test_image, \n",
    "    clinical_context=\"Adult patient with cough and fever\"\n",
    ")\n",
    "print(\"\\n✓ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification results\n",
    "print(\"=\"*60)\n",
    "print(\"CLASSIFICATION (MedSigLIP)\")\n",
    "print(\"=\"*60)\n",
    "for label, prob in sorted(results['classification'].items(), key=lambda x: x[1], reverse=True):\n",
    "    bar = \"█\" * int(prob * 25) + \"░\" * (25 - int(prob * 25))\n",
    "    print(f\"{label:25s} {bar} {prob*100:5.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "print(results['findings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DIFFERENTIAL DIAGNOSIS\")\n",
    "print(\"=\"*60)\n",
    "print(results['differential'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "print(results['recommendations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 7. Structured Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating structured report...\\n\")\n",
    "report = primacare.generate_report(\n",
    "    test_image,\n",
    "    patient_info={'age': '45', 'gender': 'Female', 'history': 'Cough x 1 week'}\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RADIOLOGY REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 8. Batch Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing on multiple samples...\\n\")\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    label = \"Pneumonia\" if sample.get('label', 0) == 1 else \"Normal\"\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Sample {i+1} | Ground Truth: {label}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    display(sample['image'].resize((150, 150)))\n",
    "    \n",
    "    # Quick classification\n",
    "    probs = classify_image(sample['image'], primacare.CXR_LABELS)\n",
    "    top = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    print(\"Top 3:\")\n",
    "    for lbl, prob in top:\n",
    "        print(f\"  {lbl}: {prob*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "========================================\n",
    "PRIMACARE AI - PROTOTYPE SUMMARY\n",
    "========================================\n",
    "\n",
    "✓ MedGemma 1.5 4B - Image analysis\n",
    "✓ MedSigLIP - Zero-shot classification\n",
    "✓ Full analysis pipeline\n",
    "✓ Structured report generation\n",
    "\n",
    "Next: Run 04_agentic_workflow.ipynb\n",
    "for the multi-agent demo.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}