{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedGemma Model Exploration\n",
    "\n",
    "**MedGemma Impact Challenge** - Model Exploration Notebook\n",
    "\n",
    "This notebook explores MedGemma 1.5 4B capabilities for the competition.\n",
    "\n",
    "**Run on:** Kaggle (GPU T4/P100) or Google Colab (GPU)\n",
    "\n",
    "**Models explored:**\n",
    "- MedGemma 1.5 4B (multimodal - images + text)\n",
    "- MedSigLIP (zero-shot classification)\n",
    "\n",
    "**Competition:** https://www.kaggle.com/competitions/med-gemma-impact-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install -q -U transformers>=4.50.0 accelerate datasets pillow huggingface-hub gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from transformers import pipeline, AutoProcessor, AutoModel\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face (required for MedGemma access)\n",
    "# You must accept HAI-DEF terms at: https://huggingface.co/google/medgemma-1.5-4b-it\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Option 1: Use Kaggle secrets\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# secrets = UserSecretsClient()\n",
    "# hf_token = secrets.get_secret(\"HF_TOKEN\")\n",
    "# login(token=hf_token)\n",
    "\n",
    "# Option 2: Interactive login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MedGemma 1.5 4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_ID = \"google/medgemma-1.5-4b-it\"\n",
    "\n",
    "print(f\"Loading {MODEL_ID}...\")\n",
    "print(\"This may take a few minutes on first run.\")\n",
    "\n",
    "# Load using pipeline API (recommended)\n",
    "pipe = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "print(\"✓ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for image analysis\n",
    "def analyze_image(image, prompt, max_tokens=2000):\n",
    "    \"\"\"Analyze a medical image with MedGemma.\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    output = pipe(text=messages, max_new_tokens=max_tokens)\n",
    "    return output[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "# Helper function for text-only questions\n",
    "def ask_question(question, max_tokens=1000):\n",
    "    \"\"\"Ask a medical question without an image.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    output = pipe(text=messages, max_new_tokens=max_tokens)\n",
    "    return output[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "print(\"✓ Helper functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test with Sample Chest X-ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample chest X-ray from Wikipedia (public domain)\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"\n",
    "response = requests.get(image_url, headers={\"User-Agent\": \"MedGemma-Demo\"})\n",
    "sample_image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Display\n",
    "print(\"Sample Chest X-ray:\")\n",
    "display(sample_image.resize((400, 400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic analysis\n",
    "print(\"Analyzing chest X-ray...\\n\")\n",
    "result = analyze_image(sample_image, \"Describe this chest X-ray in detail.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Different Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different prompt styles\n",
    "prompts = {\n",
    "    \"Findings\": \"List all findings in this chest X-ray in bullet points.\",\n",
    "    \"Differential\": \"What is your differential diagnosis based on this chest X-ray?\",\n",
    "    \"Report\": \"\"\"Generate a structured radiology report for this chest X-ray:\n",
    "1. Technique\n",
    "2. Findings\n",
    "3. Impression\"\"\",\n",
    "    \"Primary Care\": \"\"\"As a primary care physician reviewing this X-ray:\n",
    "1. Key findings\n",
    "2. Differential diagnosis\n",
    "3. Recommended next steps\"\"\",\n",
    "}\n",
    "\n",
    "for name, prompt in prompts.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROMPT TYPE: {name}\")\n",
    "    print(\"=\"*60)\n",
    "    result = analyze_image(sample_image, prompt)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load NIH Chest X-ray Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset in streaming mode (no full download needed)\n",
    "print(\"Loading NIH Chest X-ray dataset (streaming)...\")\n",
    "dataset = load_dataset(\n",
    "    \"alkzar90/NIH-Chest-X-ray-dataset\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# Get first few samples\n",
    "samples = list(dataset.take(5))\n",
    "print(f\"\\n✓ Loaded {len(samples)} samples\")\n",
    "print(f\"Sample keys: {list(samples[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore a sample\n",
    "sample = samples[0]\n",
    "print(f\"Labels: {sample.get('labels', 'N/A')}\")\n",
    "print(f\"Patient Age: {sample.get('Patient Age', 'N/A')}\")\n",
    "print(f\"Patient Gender: {sample.get('Patient Gender', 'N/A')}\")\n",
    "display(sample['image'].resize((400, 400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sample from dataset\n",
    "print(f\"Ground truth labels: {sample.get('labels', [])}\")\n",
    "print(\"\\nMedGemma Analysis:\")\n",
    "result = analyze_image(sample['image'], \"List all abnormalities visible in this chest X-ray.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test MedSigLIP (Zero-Shot Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MedSigLIP for classification\n",
    "print(\"Loading MedSigLIP...\")\n",
    "siglip_model = AutoModel.from_pretrained(\"google/medsiglip-448\").to(\"cuda\")\n",
    "siglip_processor = AutoProcessor.from_pretrained(\"google/medsiglip-448\")\n",
    "print(\"✓ MedSigLIP loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot classification function\n",
    "def classify_image(image, labels):\n",
    "    \"\"\"Zero-shot classification with MedSigLIP.\"\"\"\n",
    "    inputs = siglip_processor(\n",
    "        text=labels,\n",
    "        images=[image],\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = siglip_model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits_per_image, dim=1)[0]\n",
    "    \n",
    "    return {label: f\"{prob.item()*100:.1f}%\" for label, prob in zip(labels, probs)}\n",
    "\n",
    "# Test classification\n",
    "labels = [\n",
    "    \"normal chest x-ray\",\n",
    "    \"pneumonia\",\n",
    "    \"pleural effusion\",\n",
    "    \"cardiomegaly\",\n",
    "    \"pulmonary edema\"\n",
    "]\n",
    "\n",
    "print(\"Zero-shot classification results:\")\n",
    "results = classify_image(sample_image, labels)\n",
    "for label, prob in sorted(results.items(), key=lambda x: float(x[1][:-1]), reverse=True):\n",
    "    print(f\"  {label}: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text-Only Medical QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text-only medical knowledge\n",
    "questions = [\n",
    "    \"What are the classic findings of pneumonia on a chest X-ray?\",\n",
    "    \"A 65-year-old smoker presents with hemoptysis and weight loss. What should be considered?\",\n",
    "    \"What is the difference between consolidation and ground-glass opacity?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Q: {q}\")\n",
    "    print(\"=\"*60)\n",
    "    answer = ask_question(q)\n",
    "    print(f\"A: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiple samples\n",
    "print(\"Analyzing multiple chest X-rays...\\n\")\n",
    "\n",
    "for i, sample in enumerate(samples[:3]):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sample {i+1}\")\n",
    "    print(f\"Ground Truth: {sample.get('labels', [])}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Display thumbnail\n",
    "    display(sample['image'].resize((200, 200)))\n",
    "    \n",
    "    # Get MedGemma analysis\n",
    "    result = analyze_image(\n",
    "        sample['image'],\n",
    "        \"In one paragraph, describe the key findings in this chest X-ray.\"\n",
    "    )\n",
    "    print(f\"\\nMedGemma: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Observations & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document your observations\n",
    "observations = \"\"\"\n",
    "## Exploration Observations\n",
    "\n",
    "### Model Strengths:\n",
    "- [ ] Detailed image descriptions\n",
    "- [ ] Structured report generation\n",
    "- [ ] Medical knowledge accuracy\n",
    "- [ ] Multiple imaging modalities\n",
    "\n",
    "### Model Limitations:\n",
    "- [ ] Sensitivity to prompt wording\n",
    "- [ ] May miss subtle findings\n",
    "- [ ] Confidence calibration\n",
    "\n",
    "### Best Prompts Found:\n",
    "- \n",
    "\n",
    "### Project Ideas:\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "### Next Steps:\n",
    "- [ ] Test on pathology-specific cases\n",
    "- [ ] Evaluate on held-out data\n",
    "- [ ] Build prototype demo\n",
    "\"\"\"\n",
    "\n",
    "print(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save exploration results\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "results_summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model\": MODEL_ID,\n",
    "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
    "    \"samples_analyzed\": len(samples),\n",
    "    \"notes\": \"Initial exploration complete\"\n",
    "}\n",
    "\n",
    "print(json.dumps(results_summary, indent=2))\n",
    "\n",
    "# Uncomment to save:\n",
    "# with open('exploration_results.json', 'w') as f:\n",
    "#     json.dump(results_summary, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **MedGemma 1.5 4B** - Multimodal medical AI for image analysis and text generation\n",
    "2. **MedSigLIP** - Zero-shot medical image classification\n",
    "3. **NIH Chest X-ray Dataset** - 112K chest X-rays for training/testing\n",
    "\n",
    "**Next:** Build a prototype application in `03_prototype.ipynb`\n",
    "\n",
    "**Resources:**\n",
    "- [MedGemma Model](https://huggingface.co/google/medgemma-1.5-4b-it)\n",
    "- [MedGemma GitHub](https://github.com/Google-Health/medgemma)\n",
    "- [Competition Page](https://www.kaggle.com/competitions/med-gemma-impact-challenge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
