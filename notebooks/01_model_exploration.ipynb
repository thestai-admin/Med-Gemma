{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# MedGemma Model Exploration\n",
    "\n",
    "**MedGemma Impact Challenge** - Model Exploration Notebook\n",
    "\n",
    "This notebook explores MedGemma 1.5 4B capabilities for the competition.\n",
    "\n",
    "**Requirements:**\n",
    "- Kaggle GPU (T4/P100) or Google Colab (GPU)\n",
    "- HF_TOKEN secret with access to MedGemma\n",
    "- Accept HAI-DEF terms at: https://huggingface.co/google/medgemma-1.5-4b-it\n",
    "\n",
    "**Models explored:**\n",
    "- MedGemma 1.5 4B (multimodal - images + text)\n",
    "- MedSigLIP (zero-shot classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (skip on Kaggle - already installed)\n",
    "# Uncomment if running on Colab or locally:\n",
    "# !pip install -q -U transformers>=4.50.0 accelerate datasets pillow huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoProcessor, AutoModel\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU - REQUIRED for MedGemma\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"ERROR: GPU required! Enable GPU in notebook settings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Login\n",
    "# You must accept HAI-DEF terms at: https://huggingface.co/google/medgemma-1.5-4b-it\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Option 1: Kaggle secrets (recommended)\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    secrets = UserSecretsClient()\n",
    "    hf_token = secrets.get_secret(\"HF_TOKEN\")\n",
    "    login(token=hf_token)\n",
    "    print(\"Logged in via Kaggle secrets\")\n",
    "except:\n",
    "    # Option 2: Interactive login (Colab/local)\n",
    "    login()\n",
    "    print(\"Logged in interactively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Load MedGemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"google/medgemma-1.5-4b-it\"\n",
    "\n",
    "print(f\"Loading {MODEL_ID}...\")\n",
    "print(\"This takes 2-3 minutes on first run.\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "print(\"✓ MedGemma loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image, prompt, max_tokens=2000):\n",
    "    \"\"\"Analyze a medical image with MedGemma.\"\"\"\n",
    "    # Ensure RGB format\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    \n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": prompt}\n",
    "        ]\n",
    "    }]\n",
    "    output = pipe(text=messages, max_new_tokens=max_tokens)\n",
    "    return output[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "\n",
    "def ask_question(question, max_tokens=1000):\n",
    "    \"\"\"Ask a medical question without an image.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    output = pipe(text=messages, max_new_tokens=max_tokens)\n",
    "    return output[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "\n",
    "print(\"✓ Helper functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Test with Sample Chest X-ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample chest X-ray (public domain)\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"\n",
    "response = requests.get(image_url, headers={\"User-Agent\": \"MedGemma-Demo\"})\n",
    "sample_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "print(\"Sample Chest X-ray:\")\n",
    "display(sample_image.resize((400, 400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic analysis\n",
    "print(\"Analyzing chest X-ray...\\n\")\n",
    "result = analyze_image(sample_image, \"Describe this chest X-ray in detail.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Explore Different Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "    \"Findings\": \"List all findings in this chest X-ray in bullet points.\",\n",
    "    \"Differential\": \"What is your differential diagnosis based on this chest X-ray?\",\n",
    "    \"Report\": \"\"\"Generate a structured radiology report for this chest X-ray:\n",
    "1. Technique\n",
    "2. Findings\n",
    "3. Impression\"\"\",\n",
    "    \"Primary Care\": \"\"\"As a primary care physician reviewing this X-ray:\n",
    "1. Key findings\n",
    "2. Differential diagnosis\n",
    "3. Recommended next steps\"\"\",\n",
    "}\n",
    "\n",
    "for name, prompt in prompts.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROMPT TYPE: {name}\")\n",
    "    print(\"=\"*60)\n",
    "    result = analyze_image(sample_image, prompt)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Chest X-ray Pneumonia dataset (simpler, no script issues)\n",
    "print(\"Loading chest X-ray dataset (streaming)...\")\n",
    "dataset = load_dataset(\n",
    "    \"hf-vision/chest-xray-pneumonia\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "samples = list(dataset.take(5))\n",
    "print(f\"✓ Loaded {len(samples)} samples\")\n",
    "print(f\"Keys: {list(samples[0].keys())}\")\n",
    "print(f\"Labels: 0=Normal, 1=Pneumonia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore a sample\n",
    "sample = samples[0]\n",
    "label_name = \"Pneumonia\" if sample.get('label', 0) == 1 else \"Normal\"\n",
    "print(f\"Ground Truth: {label_name}\")\n",
    "display(sample['image'].resize((400, 400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sample from dataset\n",
    "print(f\"Ground truth: {label_name}\")\n",
    "print(\"\\nMedGemma Analysis:\")\n",
    "result = analyze_image(sample['image'], \"List all abnormalities visible in this chest X-ray.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 6. MedSigLIP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading MedSigLIP...\")\n",
    "siglip_model = AutoModel.from_pretrained(\"google/medsiglip-448\").to(\"cuda\")\n",
    "siglip_processor = AutoProcessor.from_pretrained(\"google/medsiglip-448\")\n",
    "print(\"✓ MedSigLIP loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image, labels):\n",
    "    \"\"\"Zero-shot classification with MedSigLIP.\"\"\"\n",
    "    # IMPORTANT: Convert to RGB\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    \n",
    "    inputs = siglip_processor(\n",
    "        text=labels,\n",
    "        images=[image],\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = siglip_model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits_per_image, dim=1)[0]\n",
    "    \n",
    "    return {label: prob.item() for label, prob in zip(labels, probs)}\n",
    "\n",
    "\n",
    "# Classification labels\n",
    "labels = [\n",
    "    \"normal chest x-ray\",\n",
    "    \"pneumonia\",\n",
    "    \"pleural effusion\",\n",
    "    \"cardiomegaly\",\n",
    "    \"pulmonary edema\"\n",
    "]\n",
    "\n",
    "print(\"Zero-shot classification results:\")\n",
    "results = classify_image(sample_image, labels)\n",
    "for label, prob in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    bar = \"█\" * int(prob * 30) + \"░\" * (30 - int(prob * 30))\n",
    "    print(f\"  {label:20s} {bar} {prob*100:5.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 7. Text-Only Medical QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What are the classic findings of pneumonia on a chest X-ray?\",\n",
    "    \"A 65-year-old smoker presents with hemoptysis and weight loss. What should be considered?\",\n",
    "    \"What is the difference between consolidation and ground-glass opacity?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Q: {q}\")\n",
    "    print(\"=\"*60)\n",
    "    answer = ask_question(q)\n",
    "    print(f\"A: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 8. Batch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing multiple chest X-rays...\\n\")\n",
    "\n",
    "for i, sample in enumerate(samples[:3]):\n",
    "    label_name = \"Pneumonia\" if sample.get('label', 0) == 1 else \"Normal\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sample {i+1} | Ground Truth: {label_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    display(sample['image'].resize((200, 200)))\n",
    "    \n",
    "    # Classification\n",
    "    probs = classify_image(sample['image'], labels)\n",
    "    top_3 = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    print(\"Classification:\")\n",
    "    for label, prob in top_3:\n",
    "        print(f\"  - {label}: {prob*100:.1f}%\")\n",
    "    \n",
    "    # MedGemma analysis\n",
    "    result = analyze_image(\n",
    "        sample['image'],\n",
    "        \"In one sentence, describe the key finding in this chest X-ray.\"\n",
    "    )\n",
    "    print(f\"\\nMedGemma: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model\": MODEL_ID,\n",
    "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
    "    \"samples_analyzed\": len(samples),\n",
    "    \"status\": \"Exploration complete\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(\"\\nNext: Run 03_prototype.ipynb or 04_agentic_workflow.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "**MedGemma 1.5 4B:**\n",
    "- Detailed chest X-ray descriptions\n",
    "- Structured report generation\n",
    "- Good medical knowledge\n",
    "\n",
    "**MedSigLIP:**\n",
    "- Fast zero-shot classification\n",
    "- Good for initial triage\n",
    "\n",
    "**Resources:**\n",
    "- [MedGemma Model](https://huggingface.co/google/medgemma-1.5-4b-it)\n",
    "- [Competition Page](https://www.kaggle.com/competitions/med-gemma-impact-challenge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
