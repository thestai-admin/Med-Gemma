{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":118534,"databundleVersionId":14898831,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"cell-0","cell_type":"markdown","source":"# MedGemma Model Exploration\n\n**MedGemma Impact Challenge** - Model Exploration Notebook\n\nThis notebook explores MedGemma 1.5 4B capabilities for the competition.\n\n**Requirements:**\n- Kaggle GPU (T4/P100) or Google Colab (GPU)\n- HF_TOKEN secret with access to MedGemma\n- Accept HAI-DEF terms at: https://huggingface.co/google/medgemma-1.5-4b-it\n\n**Models explored:**\n- MedGemma 1.5 4B (multimodal - images + text)\n- MedSigLIP (zero-shot classification)","metadata":{}},{"id":"cell-1","cell_type":"markdown","source":"## 1. Setup","metadata":{}},{"id":"cell-2","cell_type":"code","source":"# IMPORTANT: Run this cell FIRST - Completely disable torch dynamo\nimport os\nos.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    raise RuntimeError(\"GPU required! Enable in Settings.\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-3","cell_type":"code","source":"from transformers import AutoProcessor, AutoModelForImageTextToText, AutoModel\nfrom PIL import Image\nfrom datasets import load_dataset\nimport requests\nfrom io import BytesIO\n\nprint(\"✓ Imports ready\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-4","cell_type":"code","source":"# Hugging Face Login (Kaggle)\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nlogin(token=UserSecretsClient().get_secret(\"HF_TOKEN\"))\nprint(\"✓ Logged in via Kaggle secrets\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-5","cell_type":"markdown","source":"## 2. Load MedGemma","metadata":{}},{"id":"cell-6","cell_type":"code","source":"MODEL_ID = \"google/medgemma-1.5-4b-it\"\n\nprint(f\"Loading {MODEL_ID}...\")\nprint(\"This takes 2-3 minutes on first run.\")\n\nmedgemma_model = AutoModelForImageTextToText.from_pretrained(\n    MODEL_ID,\n    torch_dtype=torch.bfloat16,\n    device_map=\"cuda\",\n)\nmedgemma_processor = AutoProcessor.from_pretrained(MODEL_ID)\nprint(\"✓ MedGemma loaded!\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-7","cell_type":"code","source":"def analyze_image(image, prompt, max_tokens=2000):\n    \"\"\"Analyze a medical image with MedGemma.\"\"\"\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    \n    messages = [{\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": image},\n            {\"type\": \"text\", \"text\": prompt}\n        ]\n    }]\n    \n    inputs = medgemma_processor.apply_chat_template(\n        messages, \n        add_generation_prompt=True, \n        tokenize=True,\n        return_dict=True,\n        return_tensors=\"pt\"\n    ).to(\"cuda\")\n    \n    with torch.no_grad():\n        output_ids = medgemma_model.generate(\n            **inputs,\n            max_new_tokens=max_tokens,\n            do_sample=False\n        )\n    \n    generated_ids = output_ids[:, inputs[\"input_ids\"].shape[-1]:]\n    return medgemma_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\n\ndef ask_question(question, max_tokens=1000):\n    \"\"\"Ask a medical question without an image.\"\"\"\n    messages = [{\n        \"role\": \"user\",\n        \"content\": [{\"type\": \"text\", \"text\": question}]\n    }]\n    \n    inputs = medgemma_processor.apply_chat_template(\n        messages,\n        add_generation_prompt=True,\n        tokenize=True,\n        return_dict=True,\n        return_tensors=\"pt\"\n    ).to(\"cuda\")\n    \n    with torch.no_grad():\n        output_ids = medgemma_model.generate(\n            **inputs,\n            max_new_tokens=max_tokens,\n            do_sample=False\n        )\n    \n    generated_ids = output_ids[:, inputs[\"input_ids\"].shape[-1]:]\n    return medgemma_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\n\nprint(\"✓ Helper functions ready\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-8","cell_type":"markdown","source":"## 3. Test with Sample Chest X-ray","metadata":{}},{"id":"cell-9","cell_type":"code","source":"# Load sample chest X-ray (public domain)\nimage_url = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"\nresponse = requests.get(image_url, headers={\"User-Agent\": \"MedGemma-Demo\"})\nsample_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n\nprint(\"Sample Chest X-ray:\")\ndisplay(sample_image.resize((400, 400)))","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-10","cell_type":"code","source":"# Basic analysis\nprint(\"Analyzing chest X-ray...\\n\")\nresult = analyze_image(sample_image, \"Describe this chest X-ray in detail.\")\nprint(result)","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-11","cell_type":"markdown","source":"## 4. Explore Different Prompts","metadata":{}},{"id":"cell-12","cell_type":"code","source":"prompts = {\n    \"Findings\": \"List all findings in this chest X-ray in bullet points.\",\n    \"Differential\": \"What is your differential diagnosis based on this chest X-ray?\",\n    \"Report\": \"\"\"Generate a structured radiology report for this chest X-ray:\n1. Technique\n2. Findings\n3. Impression\"\"\",\n    \"Primary Care\": \"\"\"As a primary care physician reviewing this X-ray:\n1. Key findings\n2. Differential diagnosis\n3. Recommended next steps\"\"\",\n}\n\nfor name, prompt in prompts.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"PROMPT TYPE: {name}\")\n    print(\"=\"*60)\n    result = analyze_image(sample_image, prompt)\n    print(result)","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-13","cell_type":"markdown","source":"## 5. Load Dataset","metadata":{}},{"id":"cell-14","cell_type":"code","source":"# Load Chest X-ray Pneumonia dataset (simpler, no script issues)\nprint(\"Loading chest X-ray dataset (streaming)...\")\ndataset = load_dataset(\n    \"hf-vision/chest-xray-pneumonia\",\n    split=\"train\",\n    streaming=True\n)\n\nsamples = list(dataset.take(5))\nprint(f\"✓ Loaded {len(samples)} samples\")\nprint(f\"Keys: {list(samples[0].keys())}\")\nprint(f\"Labels: 0=Normal, 1=Pneumonia\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-15","cell_type":"code","source":"# Explore a sample\nsample = samples[0]\nlabel_name = \"Pneumonia\" if sample.get('label', 0) == 1 else \"Normal\"\nprint(f\"Ground Truth: {label_name}\")\ndisplay(sample['image'].resize((400, 400)))","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-16","cell_type":"code","source":"# Analyze sample from dataset\nprint(f\"Ground truth: {label_name}\")\nprint(\"\\nMedGemma Analysis:\")\nresult = analyze_image(sample['image'], \"List all abnormalities visible in this chest X-ray.\")\nprint(result)","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-17","cell_type":"markdown","source":"## 6. MedSigLIP Classification","metadata":{}},{"id":"cell-18","cell_type":"code","source":"print(\"Loading MedSigLIP...\")\nsiglip_model = AutoModel.from_pretrained(\"google/medsiglip-448\").to(\"cuda\")\nsiglip_processor = AutoProcessor.from_pretrained(\"google/medsiglip-448\")\nprint(\"✓ MedSigLIP loaded\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-19","cell_type":"code","source":"def classify_image(image, labels):\n    \"\"\"Zero-shot classification with MedSigLIP.\"\"\"\n    # IMPORTANT: Convert to RGB\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    \n    inputs = siglip_processor(\n        text=labels,\n        images=[image],\n        padding=\"max_length\",\n        return_tensors=\"pt\"\n    ).to(\"cuda\")\n    \n    with torch.no_grad():\n        outputs = siglip_model(**inputs)\n        probs = torch.softmax(outputs.logits_per_image, dim=1)[0]\n    \n    return {label: prob.item() for label, prob in zip(labels, probs)}\n\n\n# Classification labels\nlabels = [\n    \"normal chest x-ray\",\n    \"pneumonia\",\n    \"pleural effusion\",\n    \"cardiomegaly\",\n    \"pulmonary edema\"\n]\n\nprint(\"Zero-shot classification results:\")\nresults = classify_image(sample_image, labels)\nfor label, prob in sorted(results.items(), key=lambda x: x[1], reverse=True):\n    bar = \"█\" * int(prob * 30) + \"░\" * (30 - int(prob * 30))\n    print(f\"  {label:20s} {bar} {prob*100:5.1f}%\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-20","cell_type":"markdown","source":"## 7. Text-Only Medical QA","metadata":{}},{"id":"cell-21","cell_type":"code","source":"questions = [\n    \"What are the classic findings of pneumonia on a chest X-ray?\",\n    \"A 65-year-old smoker presents with hemoptysis and weight loss. What should be considered?\",\n    \"What is the difference between consolidation and ground-glass opacity?\",\n]\n\nfor q in questions:\n    print(f\"\\n{'='*60}\")\n    print(f\"Q: {q}\")\n    print(\"=\"*60)\n    answer = ask_question(q)\n    print(f\"A: {answer}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-22","cell_type":"markdown","source":"## 8. Batch Analysis","metadata":{}},{"id":"cell-23","cell_type":"code","source":"print(\"Analyzing multiple chest X-rays...\\n\")\n\nfor i, sample in enumerate(samples[:3]):\n    label_name = \"Pneumonia\" if sample.get('label', 0) == 1 else \"Normal\"\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Sample {i+1} | Ground Truth: {label_name}\")\n    print(\"=\"*60)\n    \n    display(sample['image'].resize((200, 200)))\n    \n    # Classification\n    probs = classify_image(sample['image'], labels)\n    top_3 = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:3]\n    print(\"Classification:\")\n    for label, prob in top_3:\n        print(f\"  - {label}: {prob*100:.1f}%\")\n    \n    # MedGemma analysis\n    result = analyze_image(\n        sample['image'],\n        \"In one sentence, describe the key finding in this chest X-ray.\"\n    )\n    print(f\"\\nMedGemma: {result}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-24","cell_type":"markdown","source":"## 9. Summary","metadata":{}},{"id":"cell-25","cell_type":"code","source":"import json\nfrom datetime import datetime\n\nsummary = {\n    \"timestamp\": datetime.now().isoformat(),\n    \"model\": MODEL_ID,\n    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n    \"samples_analyzed\": len(samples),\n    \"status\": \"Exploration complete\"\n}\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"EXPLORATION SUMMARY\")\nprint(\"=\"*60)\nprint(json.dumps(summary, indent=2))\nprint(\"\\nNext: Run 03_prototype.ipynb or 04_agentic_workflow.ipynb\")","metadata":{},"outputs":[],"execution_count":null},{"id":"cell-26","cell_type":"markdown","source":"---\n\n## Key Findings\n\n**MedGemma 1.5 4B:**\n- Detailed chest X-ray descriptions\n- Structured report generation\n- Good medical knowledge\n\n**MedSigLIP:**\n- Fast zero-shot classification\n- Good for initial triage\n\n**Resources:**\n- [MedGemma Model](https://huggingface.co/google/medgemma-1.5-4b-it)\n- [Competition Page](https://www.kaggle.com/competitions/med-gemma-impact-challenge)","metadata":{}}]}